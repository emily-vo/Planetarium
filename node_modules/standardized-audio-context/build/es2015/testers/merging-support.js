var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
var __param = (this && this.__param) || function (paramIndex, decorator) {
    return function (target, key) { decorator(target, key, paramIndex); }
};
import { Inject, Injectable } from '@angular/core';
import { unpatchedAudioContextConstructor } from '../providers/unpatched-audio-context-constructor';
/**
 * Firefox up to version 44 had a bug which resulted in a misbehaving ChannelMergerNode. If one of
 * its channels would be unconnected the remaining channels were somehow upmixed to spread the
 * signal across all available channels.
 */
let MergingSupportTester = class MergingSupportTester {
    constructor(_UnpatchedAudioContext) {
        this._UnpatchedAudioContext = _UnpatchedAudioContext;
    }
    test() {
        if (this._UnpatchedAudioContext === null) {
            return Promise.resolve(false);
        }
        const audioContext = new this._UnpatchedAudioContext();
        const audioBufferSourceNode = audioContext.createBufferSource();
        const audioBuffer = audioContext.createBuffer(2, 2, audioContext.sampleRate);
        const channelMergerNode = audioContext.createChannelMerger(2);
        const scriptProcessorNode = audioContext.createScriptProcessor(256);
        return new Promise((resolve) => {
            let startTime;
            // @todo Safari does not play/loop 1 sample buffers. This should be patched.
            audioBuffer.getChannelData(0)[0] = 1;
            audioBuffer.getChannelData(0)[1] = 1;
            audioBuffer.getChannelData(1)[0] = 1;
            audioBuffer.getChannelData(1)[1] = 1;
            audioBufferSourceNode.buffer = audioBuffer;
            audioBufferSourceNode.loop = true;
            scriptProcessorNode.onaudioprocess = (event) => {
                const channelData = event.inputBuffer.getChannelData(1);
                const length = channelData.length;
                for (let i = 0; i < length; i += 1) {
                    if (channelData[i] !== 0) {
                        resolve(false);
                        return;
                    }
                }
                if (startTime + (1 / audioContext.sampleRate) < event.playbackTime) {
                    resolve(true);
                }
            };
            audioBufferSourceNode.connect(channelMergerNode, 0, 0);
            channelMergerNode.connect(scriptProcessorNode);
            scriptProcessorNode.connect(audioContext.destination);
            startTime = audioContext.currentTime;
            audioBufferSourceNode.start(startTime);
        })
            .then((result) => {
            audioBufferSourceNode.stop();
            audioBufferSourceNode.disconnect();
            channelMergerNode.disconnect();
            scriptProcessorNode.disconnect();
            audioContext.close();
            return result;
        });
    }
};
MergingSupportTester = __decorate([
    Injectable(),
    __param(0, Inject(unpatchedAudioContextConstructor))
], MergingSupportTester);
export { MergingSupportTester };
//# sourceMappingURL=merging-support.js.map